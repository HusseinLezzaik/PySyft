{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb32e59-4cb7-4980-9284-270b26a53722",
   "metadata": {},
   "source": [
    "# Medical Federated Learning Program - Data Science\n",
    "<img src=\"imgs/heading_title.jpg\" style=\"width: 100%; margin:0;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957c250",
   "metadata": {},
   "source": [
    "<img src=\"imgs/heading_recap.png\" style=\"width: 100%; margin:0;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501351e3",
   "metadata": {},
   "source": [
    "<img src=\"imgs/heading_ds.png\" style=\"width: 100%; margin:0;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22dc53",
   "metadata": {},
   "source": [
    "![heading_overview_1](imgs/heading_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf211e8",
   "metadata": {},
   "source": [
    "<img src=\"imgs/login_tab.png\" style=\"width: 664px; margin:0;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc512ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "\n",
    "ds_domain_node_1 = sy.login(\n",
    "    email=\"sam@stargate.net\", \n",
    "    password=\"changethis\", \n",
    "    port=8081\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e9d88",
   "metadata": {},
   "source": [
    "<img src=\"imgs/tab_list_datasets.png\" style=\"width: 664px; margin:0;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_domain_node_1.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be929fe1",
   "metadata": {},
   "source": [
    "<img src=\"imgs/tab_pointer_tensor.png\" style=\"width: 100%; margin:0;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b3edd-5d0a-49da-bb38-a0edda167109",
   "metadata": {},
   "source": [
    "<img src=\"imgs/tab_dataset_pointer.png\" style=\"width: 664px; margin:0;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d0cc5-d47e-4306-86ef-49cc7415e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds_domain_node_1.datasets[0][\"data\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb7762-fd24-4b9f-9e04-6c6a68588b3b",
   "metadata": {},
   "source": [
    "## Step 4: Working with data you don't have: Remote Procedure Calls\n",
    "\n",
    "So now we know that **Tensor Pointers** let you access data on another domain node without having to make a copy of it.\n",
    "But this is only half the story; afterall, we don't just want to access data, we want to *work with it!* How do we do that?\n",
    "\n",
    "The answer is something called **Remote Procedure Calls**. Let's start with our tensor pointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15971c8d-992f-43e9-af23-92c66b5b9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.public_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb2dab-d797-4c2f-a89b-a0c63304a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb71677-a848-4df7-8a25-f0fa40ac8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.public_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ecfea-7550-496e-899b-81af1c75dfa7",
   "metadata": {},
   "source": [
    "## Step 5:  Getting results you can see: Differential Privacy\n",
    "\n",
    "To recap: \n",
    "- We now know that **Tensor Pointers** give a data scientist the ability to access data remotely\n",
    "- They can work on remote data (using **Remote Procedure Calls**) without physically having it on their device!\n",
    "\n",
    "Now let's say you've done your analysis. How do you actually get results? And how do we make sure the data scientist seeing the results of their analysis doesn't invade or violate anyone's privacy?\n",
    "\n",
    "The answer lies in something called **Differential Privacy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c210323-eadd-428e-a2e9-b56bac9a6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_domain_node_1.privacy_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d67a3-c18c-4380-8da9-c12a555589f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transformed_data.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb6e73-29bf-4318-97d2-94eb0f785606",
   "metadata": {},
   "source": [
    "As you can see, this failed since our data scientist is trying to download raw data that they don't have the permission for.\n",
    "\n",
    "They would retrieve this data by spending something called a **privacy budget.** They specify how much noise they want to add, and accordingly, their privacy budget gets deducted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d70cda-6b91-4392-a6bd-a795688903b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr = data.publish(sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e2552-54ff-46ee-b9d9-0a1f7b308634",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ptr.get()\n",
    "res.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1a828-4a10-4261-9315-8d8bed6a270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_domain_node_1.privacy_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c381a9-587e-40d6-9abc-64d974834869",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57796128-72b7-43e9-97c6-8fb19cae53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pointer = transformed_data.publish(sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4993c-83d8-42ee-bac2-a255db63aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = new_pointer.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142f252-aaa3-47cb-805b-c485180a2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ad113-7af5-4b7c-9f1e-864f8a500227",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb031b-a68d-45cc-8cb3-b4fee5bd444c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 6: Combining data from many nodes: Secure Multiparty Computation\n",
    "\n",
    "Okay- so we created a Tensor Pointer, used its remote procedure calls to conduct an experiment, and got the result by spending some privacy budget. This combination lets you use domain from one domain node. But what if you wanted to combine data from several domain nodes?\n",
    "\n",
    "This is possible through a cryptographic tool called **Secure Multiparty Computation**, or SMPC for short.\n",
    "\n",
    "Let's start by logging onto a second domain node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab6eba-4859-4ba4-bf65-73f6ba69ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_domain_node_2 = sy.login(email=\"sam@stargate.net\", password=\"changethis\", port=8082)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6dcb4-8fed-4e00-9ac2-c88207a02ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_domain_node_2.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7b5c5-939f-48f9-98f8-7dc54ca81a0f",
   "metadata": {},
   "source": [
    "Let's say we want to take the two example datasets, and see the result of their addition. We would do this by simply adding the two tensor pointers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af2fb0-673a-45f8-a163-2056f7c25418",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer1 = ds_domain_node_1.datasets[0][\"data\"]\n",
    "pointer2 = ds_domain_node_2.datasets[0][\"data\"]\n",
    "\n",
    "pointer_to_result = pointer1 + pointer2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7b924-7b01-442c-937e-3256e9c04d27",
   "metadata": {},
   "source": [
    "Once we have a pointer to the result, we can spend some privacy budget by publishing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffa258-bdcf-46d6-9df5-fcb40ba96762",
   "metadata": {},
   "outputs": [],
   "source": [
    "published_result = pointer_to_result.publish(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7980720",
   "metadata": {},
   "outputs": [],
   "source": [
    "published_result.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb93fa-4e58-43b1-861e-221cdf3d6c9d",
   "metadata": {},
   "source": [
    "The power of SMPC is that it lets us calculate and use data that's stored in two separate places (maybe even separated by thousands of miles!) without exposing any private information to any party."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f7090",
   "metadata": {},
   "source": [
    "## Step 7: Finding data you don't have: Network Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6952d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sy.networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b30ea-3984-4828-8d17-c4c2e8af4845",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Learning more from data: Machine Learning\n",
    "\n",
    "So far, all of the techniques explained previously have focused on providing privacy and security, in order to get access to more data.\n",
    "\n",
    "This final technique focuses more on what we'll be using the data *to do.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fe015-8aa3-4009-beaf-e51a4665c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "for j in range(60000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5374ff9-e3cd-4d74-9ea7-2b50a396347d",
   "metadata": {},
   "source": [
    "## Everything combined: PySyft\n",
    "\n",
    "PySyft combines all of these tools and techniques, and improves upon many of them. We'll soon be training a model with data across 100 domain nodes, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3399136-1fe3-4e9c-a02f-c8a42a47015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get pointers to the training data on both domain nodes!\n",
    "domain_node_1_train_data = ds_domain_node_1.datasets[-1][\"training_data\"]\n",
    "domain_node_1_targets_data = ds_domain_node_1.datasets[-1][\"training_targets\"]\n",
    "domain_node_2_train_data = ds_domain_node_2.datasets[-1][\"training_data\"]\n",
    "domain_node_2_targets_data = ds_domain_node_2.datasets[-1][\"training_targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1822db-3fd3-4ab7-ace2-fc1e2a6463df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine all the training data!\n",
    "train_data = domain_node_1_train_data.concatenate(domain_node_2_train_data)\n",
    "targets_data = domain_node_1_targets_data.concatenate(domain_node_2_targets_data)\n",
    "X = train_data\n",
    "y = targets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9273f4-fbf5-4d04-9cd2-29dd95591497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x,deriv=False):\n",
    "    if deriv==True:\n",
    "        return x>0\n",
    "    return x*(x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f2619-a61b-43b7-ad84-e1abc891ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0_weights = 2*np.random.random((3,4)) - 1\n",
    "layer1_weights = 2*np.random.random((4,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9f4bf-b643-4fe6-a159-f3ee4cac941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1):\n",
    "    # Forward propagation\n",
    "    layer1_inputs = relu(X @ layer0_weights)  ; layer1_inputs.block\n",
    "    layer2_inputs = relu(layer1_inputs @ layer1_weights) ; layer2_inputs.block \n",
    "    \n",
    "    # Calculate errors\n",
    "    layer2_inputs_delta = (y - layer2_inputs)* relu(layer2_inputs,deriv=True) ; layer2_inputs_delta.block\n",
    "    layer1_inputs_delta = (layer2_inputs_delta@(layer1_weights.T)) * relu(layer1_inputs,deriv=True) ; layer1_inputs_delta.block\n",
    "    \n",
    "    # Update weights\n",
    "    layer1_weights  = layer1_weights + layer1_inputs.T @ layer2_inputs_delta ; layer1_weights.block\n",
    "    layer0_weights =  layer0_weights + X.T @ layer1_inputs_delta ; layer0_weights.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687bb3f3-8c33-40ff-85db-d1b98e121af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0_weights_dp = layer0_weights.publish(sigma=1e4)\n",
    "layer1_weights_dp = layer1_weights.publish(sigma=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd00e4c-9b24-44ce-b702-effbd0faa022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer0_weights_dp.get_copy())\n",
    "print(layer1_weights_dp.get_copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ea1ad-6027-4c81-a036-0aac69da4da2",
   "metadata": {},
   "source": [
    "And voila! The model weights have updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58276a94-aba0-4aa6-a43c-a29f333d2c99",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Thanks for following along! I hope you walk away from this with a better understanding of how PySyft works, and also get a sense of where we're going with all this. Very soon, we'll be using the domain nodes you setup to train an AI model on breast cancer data that's across 100 institutions. We're very humbled and grateful to get the chance to help all of you.\n",
    "\n",
    "If you have any questions or concerns, please feel free to post a message in the #support Slack channel! :)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "630449982b6186a6531308cd76ed4d510e9db65154e43844c2906c6a20ad2a6d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
